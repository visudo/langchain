{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35130609-b765-41f4-b5c4-3302bed8198e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "import httpx\n",
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(temperature=0.0,api_key=os.environ['OPENAI_API_KEY'],base_url=\"https://api-inference.modelscope.cn/v1/\", http_client=httpx.Client(verify=False),model=\"deepseek-ai/DeepSeek-R1-Distill-Qwen-7B\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c303dc48-6412-411c-bd62-44e808ef07b6",
   "metadata": {},
   "source": [
    "#### 1. ConversationBufferMemoryÔºàÂØπËØùÁºìÂ≠òËÆ∞ÂøÜÔºâ\n",
    "ËøôÁßçËÆ∞ÂøÜÂÖÅËÆ∏Â≠òÂÇ®Ê∂àÊÅØÔºåÁÑ∂Âêé‰ªéÂèòÈáè‰∏≠ÊèêÂèñÊ∂àÊÅØ„ÄÇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c68745c-9291-4685-bc82-2f9e595fc1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "memory = ConversationBufferMemory()\n",
    "conversation = ConversationChain(llm=llm, memory = memory,\n",
    "                                 verbose=True#Êü•ÁúãLangchainÂÆûÈôÖ‰∏äÂú®ÂÅö‰ªÄ‰πàÔºåËÆæ‰∏∫FALSEÁöÑËØùÂè™ÁªôÂá∫ÂõûÁ≠îÔºåÁúãÂà∞‰∏çÂà∞‰∏ãÈù¢ÁªøËâ≤ÁöÑÂÜÖÂÆπ\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "613b455f-03cc-4492-a78c-d076f490b117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi, my name is andy\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hello, Andy! How can I assist you today? üòä'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Hi, my name is andy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e83a2475-525d-459d-a07c-42019217461b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi, my name is andy\n",
      "AI: Hello, Andy! How can I assist you today? üòä\n",
      "Human: What is 1+1?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The sum of 1 plus 1 is 2. \\n\\n**Answer:** 1 + 1 equals 2.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What is 1+1?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aef54468-2a59-49ef-ab71-2bbe26c5bc6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Hi, my name is andy\n",
      "AI: Hello, Andy! How can I assist you today? üòä\n",
      "Human: What is 1+1?\n",
      "AI: The sum of 1 plus 1 is 2. \n",
      "\n",
      "**Answer:** 1 + 1 equals 2.\n"
     ]
    }
   ],
   "source": [
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "619f0c50-2673-4d15-9015-0883e316b9f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: Hi, my name is andy\\nAI: Hello, Andy! How can I assist you today? üòä\\nHuman: What is 1+1?\\nAI: The sum of 1 plus 1 is 2. \\n\\n**Answer:** 1 + 1 equals 2.'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f633cbf-e570-4fcb-852d-127301e72084",
   "metadata": {},
   "source": [
    "#### 2. ConversationBufferWindowMemoryÔºàÂØπËØùÁºìÂ≠òÁ™óÂè£ËÆ∞ÂøÜÔºâ\n",
    "ÈöèÁùÄÂØπËØùÂèòÂæóË∂äÊù•Ë∂äÈïøÔºåÊâÄÈúÄÁöÑÂÜÖÂ≠òÈáè‰πüÂèòÂæóÈùûÂ∏∏Èïø„ÄÇÂ∞ÜÂ§ßÈáèÁöÑtokensÂèëÈÄÅÂà∞LLMÁöÑÊàêÊú¨Ôºå‰πü‰ºöÂèòÂæóÊõ¥Âä†ÊòÇË¥µ,Ëøô‰πüÂ∞±ÊòØ‰∏∫‰ªÄ‰πàAPIÁöÑË∞ÉÁî®Ë¥πÁî®ÔºåÈÄöÂ∏∏ÊòØÂü∫‰∫éÂÆÉÈúÄË¶ÅÂ§ÑÁêÜÁöÑtokensÊï∞ÈáèËÄåÊî∂Ë¥πÁöÑ„ÄÇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "190b1693-e87c-41a3-8fe7-f028a092e6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "memory = ConversationBufferWindowMemory(k=1)     # k=1Ë°®ÊòéÂè™‰øùÁïô‰∏Ä‰∏™ÂØπËØùËÆ∞ÂøÜ    \n",
    "conversation = ConversationChain(llm=llm, memory = memory,\n",
    "    verbose=True    #ËøôÈáåÊîπ‰∏∫FALSE‰∏çÊòæÁ§∫ÊèêÁ§∫Ôºå‰Ω†ÂèØ‰ª•Â∞ùËØï‰øÆÊîπ‰∏∫TRUEÂêéÁöÑÁªìÊûú\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "37114b47-95fe-48e9-94b3-287327a624c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi, my name is andy\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hello, Andy! How can I assist you today?'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Hi, my name is andy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c0492917-12aa-4f5e-9d44-61bd63209a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi, my name is andy\n",
      "AI: Hello, Andy! How can I assist you today?\n",
      "Human: What is 1+1?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The sum of 1 and 1 is 2. \\n\\n**Step-by-Step Explanation:**\\n\\n1. Start with the number 1.\\n2. Add another 1 to it.\\n3. The total is 2.\\n\\nThus, 1 + 1 equals 2.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What is 1+1?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "53a9dbdc-6443-4863-aa04-d6672ff68a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: What is 1+1?\n",
      "AI: The sum of 1 and 1 is 2. \n",
      "\n",
      "**Step-by-Step Explanation:**\n",
      "\n",
      "1. Start with the number 1.\n",
      "2. Add another 1 to it.\n",
      "3. The total is 2.\n",
      "\n",
      "Thus, 1 + 1 equals 2.\n",
      "Human: What is my name?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I don't have a name, but I'm here to help you with whatever you need!\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What is my name?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a11ead-ba94-4d77-91dc-9803b5043a9a",
   "metadata": {},
   "source": [
    "#### 3. ConversationTokenBufferMemoryÔºàÂØπËØùtokenÁºìÂ≠òËÆ∞ÂøÜÔºâ\n",
    "‰ΩøÁî®ÂØπËØùtokenÁºìÂ≠òËÆ∞ÂøÜÔºåÂÜÖÂ≠òÂ∞ÜÈôêÂà∂‰øùÂ≠òÁöÑtokenÊï∞Èáè„ÄÇÂ¶ÇÊûútokenÊï∞ÈáèË∂ÖÂá∫ÊåáÂÆöÊï∞ÁõÆÔºåÂÆÉ‰ºöÂàáÊéâËøô‰∏™ÂØπËØùÁöÑÊó©ÊúüÈÉ®ÂàÜ ‰ª•‰øùÁïô‰∏éÊúÄËøëÁöÑ‰∫§ÊµÅÁõ∏ÂØπÂ∫îÁöÑtokenÊï∞ÈáèÔºå‰ΩÜ‰∏çË∂ÖËøátokenÈôêÂà∂„ÄÇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0daaffa0-081b-4c08-9f27-a0d8ba5aa5d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -q tiktoken "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00e76d49-f2e3-4050-9624-111eb689f960",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "import httpx\n",
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(temperature=0.0,api_key=os.environ['OPENAI_API_KEY'],base_url=\"https://api-inference.modelscope.cn/v1/\", http_client=httpx.Client(verify=False),model=\"deepseek-ai/DeepSeek-R1-Distill-Qwen-7B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8034c6fd-9a9f-4fc2-b22e-0fdb8739278e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationTokenBufferMemory\n",
    "memory = ConversationTokenBufferMemory(llm=llm, max_token_limit=10 # ÈôêÂà∂ÊúÄÂ§ß10‰∏™token\n",
    "                                      )\n",
    "memory.save_context({\"input\": \"AI is what?!\"},\n",
    "                    {\"output\": \"Amazing!\"})\n",
    "memory.save_context({\"input\": \"Backpropagation is what?\"},\n",
    "                    {\"output\": \"Beautiful!\"})\n",
    "memory.save_context({\"input\": \"Chatbots are what?\"}, \n",
    "                    {\"output\": \"Charming!\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ddab6e12-cad6-4ab1-8c7d-e5a6eddb2e87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'AI: Charming!'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f41581d-2e7d-4d45-b44b-943d6e967628",
   "metadata": {},
   "source": [
    "#### 4. ConversationSummaryBufferMemoryÔºàÂØπËØùÊëòË¶ÅÁºìÂ≠òËÆ∞ÂøÜÔºâ\n",
    "ËøôÁßçMemoryÁöÑÊÉ≥Ê≥ïÊòØÔºå‰∏çÊòØÂ∞ÜÂÜÖÂ≠òÈôêÂà∂‰∏∫Âü∫‰∫éÊúÄËøëÂØπËØùÁöÑÂõ∫ÂÆöÊï∞ÈáèÁöÑtokenÊàñÂõ∫ÂÆöÊï∞ÈáèÁöÑÂØπËØùÊ¨°Êï∞Á™óÂè£ÔºåËÄåÊòØ‰ΩøÁî®LLMÁºñÂÜôÂà∞ÁõÆÂâç‰∏∫Ê≠¢ÂéÜÂè≤ÂØπËØùÁöÑÊëòË¶ÅÔºåÂπ∂Â∞ÜÂÖ∂‰øùÂ≠ò"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1732aa32-e5d9-458b-93e5-b6d92c8019e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "# create a long string\n",
    "schedule = \"There is a meeting at 8am with your product team. \\\n",
    "You will need your powerpoint presentation prepared. \\\n",
    "9am-12pm have time to work on your LangChain \\\n",
    "project which will go quickly because Langchain is such a powerful tool. \\\n",
    "At Noon, lunch at the italian resturant with a customer who is driving \\\n",
    "from over an hour away to meet you to understand the latest in AI. \\\n",
    "Be sure to bring your laptop to show the latest LLM demo.\"\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(llm=llm, max_token_limit=100)   #‰ΩøÁî®ÂØπËØùÊëòË¶ÅÁºìÂ≠òËÆ∞ÂøÜ\n",
    "memory.save_context({\"input\": \"Hello\"}, {\"output\": \"What's up\"})\n",
    "memory.save_context({\"input\": \"Not much, just hanging\"},\n",
    "                    {\"output\": \"Cool\"})\n",
    "memory.save_context({\"input\": \"What is on the schedule today?\"}, \n",
    "                    {\"output\": f\"{schedule}\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c6f4d0d8-69ba-4949-87b1-f0617a00719f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'System: The human asks what the AI thinks of artificial intelligence. The AI thinks AI is a force for good because it will help humans reach their full potential. The human greets the AI, they exchange casual greetings, and the human asks about the AI\\'s schedule. The AI responds with \"Cool.\"\\nAI: There is a meeting at 8am with your product team. You will need your powerpoint presentation prepared. 9am-12pm have time to work on your LangChain project which will go quickly because Langchain is such a powerful tool. At Noon, lunch at the italian resturant with a customer who is driving from over an hour away to meet you to understand the latest in AI. Be sure to bring your laptop to show the latest LLM demo.'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "17d1bd69-06f0-4565-8a3f-56b4369c432c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "conversation = ConversationChain(llm=llm, memory = memory, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ed01f1f-c426-4012-8d5f-528955c15201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "System: The human asks what the AI thinks of artificial intelligence. The AI thinks AI is a force for good because it will help humans reach their full potential. The human greets the AI, they exchange casual greetings, and the human asks about the AI's schedule. The AI responds with \"Cool.\"\n",
      "AI: There is a meeting at 8am with your product team. You will need your powerpoint presentation prepared. 9am-12pm have time to work on your LangChain project which will go quickly because Langchain is such a powerful tool. At Noon, lunch at the italian resturant with a customer who is driving from over an hour away to meet you to understand the latest in AI. Be sure to bring your laptop to show the latest LLM demo.\n",
      "Human: What would be a good demo to show?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'That sounds like a fantastic idea! A fun and interactive demo would definitely make a great impression. How about setting up a mini \"AI assistent\" game or challenge at the restaurant? You could create a fun, interactive experience where the AI demonstrates its problem-solving skills, like playing a quick game of 20 Questions, or helping with a fun trivia quiz. Alternatively, you could showcase an AI-powered interactive art installation or a creative project that brings AI to life in a playful way. The key is to make it engaging and show how AI can add value to everyday experiences. What do you think?'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What would be a good demo to show?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a81342bd-51cf-4ed8-97b9-6e91c16ac20e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'System: The human asks what the AI thinks of artificial intelligence. The AI thinks AI is a force for good because it will help humans reach their full potential. The human greets the AI, they exchange casual greetings, and the human asks about the AI\\'s schedule. The AI responds with \"Cool.\" The AI provides a detailed schedule: a meeting at 8am with the product team, 9am-12pm working on the LangChain project, a noon lunch at an Italian restaurant with a customer, and a demo idea for a fun and interactive experience like a mini \"AI assistant\" game or an AI-powered interactive art installation. The human asks for a good demo, and the AI suggests ideas like a game of 20 Questions or a trivia quiz to showcase AI\\'s problem-solving skills.'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})   #ÊëòË¶ÅËÆ∞ÂΩïÊõ¥Êñ∞‰∫Ü"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b043103d-fafd-4a5f-b66b-e7f4aca8a0af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
